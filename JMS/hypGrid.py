import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor

def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

# === ë°ì´í„° ë¡œë“œ ===
df = pd.read_csv("new_data.csv", encoding="utf-8")  # ğŸ” ì‹ ì…ìƒìš©ì´ë©´ new_data.csvë¡œ ë³€ê²½
target = "ì¤‘ë„íƒˆë½í•™ìƒ(ì‹ ì…ìƒ)ë¹„ìœ¨(%)"

features = [
    "ì •ì›ë‚´ ì‹ ì…ìƒ ì¶©ì›ìœ¨(%)", "ê¸°ìˆ™ì‚¬ ìˆ˜ìš©ë¥ ", "1ì¸ë‹¹ì¥í•™ê¸ˆ", "ì†Œê·œëª¨ ê°•ì¢Œ ë¹„ìœ¨",
    "ì „ì„êµì› 1ì¸ë‹¹ í•™ìƒìˆ˜(ì •ì›ê¸°ì¤€)", "ì·¨ì—…ë¥ ", "ì§„í•™ë¥ ", "ê°€ì¤‘ í‰ê·  ì¬í•™ìƒ ì¶©ì›ìœ¨(%)"
]

required = features + [target]
df_clean = df.dropna(subset=required)

X = df_clean[features]
y = df_clean[target]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# === í•˜ì´í¼íŒŒë¼ë¯¸í„° í›„ë³´
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.05, 0.1, 0.2]
}

# === GridSearchCV ì ìš©
grid = GridSearchCV(
    XGBRegressor(tree_method='hist', random_state=42),
    param_grid,
    scoring='neg_root_mean_squared_error',
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid.fit(X_train, y_train)

# === ìµœì  ëª¨ë¸ë¡œ í‰ê°€
best_model = grid.best_estimator_
y_pred = best_model.predict(X_test)

print("\nğŸ“Œ Best Params:", grid.best_params_)
print(f"âœ… ìµœì  ëª¨ë¸ RMSE: {rmse(y_test, y_pred):.4f}")
print(f"âœ… ìµœì  ëª¨ë¸ RÂ²: {r2_score(y_test, y_pred):.4f}")
